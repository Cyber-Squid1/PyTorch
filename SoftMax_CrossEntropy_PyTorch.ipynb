{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOTWNH8sZfnQDUvC9KGacfY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cyber-Squid1/PyTorch/blob/main/SoftMax_CrossEntropy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JmlRR3byRMBY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    return np.exp(x)/np.sum(np.exp(x),axis=0)"
      ],
      "metadata": {
        "id": "edqQ_b5vRr_W"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.array([2,1,4])\n",
        "output=softmax(x)\n",
        "print(\"Output is: \",output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FFdbKRjRsY3",
        "outputId": "1eb4e6d0-5095-48d8-d7a8-29b88e5486ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output is:  [0.1141952  0.04201007 0.84379473]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor([2,1,4],dtype=torch.float32)\n",
        "output=torch.softmax(x,dim=0)\n",
        "print(\"Output is: \",output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRv96DC9RsbX",
        "outputId": "d4be3d8b-0573-453f-9856-01549f628cd0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output is:  tensor([0.1142, 0.0420, 0.8438])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cross entropy\n",
        "def CrossEntropy(actual,predicted):\n",
        "    loss = -(np.sum(actual * np.log(predicted)))\n",
        "    return loss\n",
        "\n",
        "y=np.array([0,0,1]) # one hot encoded vector to_categorical function in Keras\n",
        "y_pred_good=np.array([0.1,0.1,0.8])\n",
        "y_pred_bad=np.array([0.1,0.8,0.1])\n",
        "output_good=CrossEntropy(y,y_pred_good)\n",
        "output_bad=CrossEntropy(y,y_pred_bad)\n",
        "print(\"Good loss output: \",output_good)\n",
        "print(\"Bad loss output: \",output_bad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWKAWnOvRsdo",
        "outputId": "0dd17c13-537c-4a83-d716-bcf01963db21"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good loss output:  0.2231435513142097\n",
            "Bad loss output:  2.3025850929940455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=nn.CrossEntropyLoss() # applies LogSoftmax and negative log likelihood loss by default\n",
        "\n",
        "y=torch.tensor([0]) # give only class name not one hot encoded vector\n",
        "\n",
        "y_pred_good=torch.tensor([[2.0,1.0,0.1]]) # size= n_samples * n_classes i.e 1*3\n",
        "y_pred_bad=torch.tensor([[0.2,6.0,3.0]])\n",
        "\n",
        "good_output=loss(y_pred_good,y)\n",
        "bad_output=loss(y_pred_bad,y)\n",
        "\n",
        "print(\"Good loss output: \",good_output.item())\n",
        "print(\"Bad loss output: \",bad_output.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Z6JMm9XRsh2",
        "outputId": "31e7d616-cb74-48f4-d6cb-0741c4831613"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good loss output:  0.4170299470424652\n",
            "Bad loss output:  5.851467132568359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# corss entropy loss for multiple samples\n",
        "# for the first output the correct output label is 2, 0 for second and label 1 for third prediction\n",
        "y=torch.tensor([2,0,1]) # multiple correct classes can be given\n",
        "\n",
        "y_pred_good=torch.tensor([ [1.2,1.0,4.1], [2.0,1.0,0.1], [1.0,6.0,0.1] ]) # size= n_samples * n_classes i.e 3*3\n",
        "y_pred_bad=torch.tensor([ [0.2,6.0,3.0], [1.0,1.0,3.1], [2.0,1.0,6.1] ])\n",
        "\n",
        "good_output=loss(y_pred_good,y)\n",
        "bad_output=loss(y_pred_bad,y)\n",
        "\n",
        "print(\"Good loss output: \",good_output.item())\n",
        "print(\"Bad loss output: \",bad_output.item())\n",
        "\n",
        "_,prediction1=torch.max(y_pred_good,1)\n",
        "_,prediction2=torch.max(y_pred_bad,1)\n",
        "print(\"Good class predictions: \",prediction1)\n",
        "print(\"Bad class predictions: \",prediction2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBIVvoO1RsjO",
        "outputId": "2053beb3-e040-4f18-aea0-55b5ef702c53"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good loss output:  0.17394621670246124\n",
            "Bad loss output:  3.4976494312286377\n",
            "Good class predictions:  tensor([2, 0, 1])\n",
            "Bad class predictions:  tensor([1, 2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Network for multi class classification\n",
        "# we do not apply softmax function at the end during forward pass in multi class classification when using nn.CrossEntropyLoss()\n",
        "class NeuralNetworkMultiClass(nn.Module):\n",
        "    def __init__(self,in_size,hidden_size,num_classes):\n",
        "        super(NeuralNetworkMultiClass,self).__init__()\n",
        "        self.l1=nn.Linear(in_size,hidden_size)\n",
        "        self.relu1=nn.ReLU()\n",
        "        self.l2=nn.Linear(hidden_size,num_classes)\n",
        "\n",
        "    def forward(self,x):\n",
        "        z=self.l1(x)\n",
        "        z=self.relu1(z)\n",
        "        z=self.l2(z)\n",
        "        return z\n",
        "\n",
        "model=NeuralNetworkMultiClass(in_size=28*28,hidden_size=5,num_classes=3)\n",
        "criterion=nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "ouhpTsDbWkVy"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Network for binary class classification\n",
        "# we need to apply sigmoid function at the end for binary class classification when using nn.BCELoss()\n",
        "class NeuralNetworkBinaryClass(nn.Module):\n",
        "    def __init__(self,in_size,hidden_size):\n",
        "        super(NeuralNetworkBinaryClass,self).__init__()\n",
        "        self.l1=nn.Linear(in_size,hidden_size)\n",
        "        self.relu1=nn.ReLU()\n",
        "        self.l2=nn.Linear(hidden_size,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        z=self.l1(x)\n",
        "        z=self.relu1(z)\n",
        "        z=self.l2(z)\n",
        "        y_pred=torch.sigmoid(z)\n",
        "        return y_pred\n",
        "\n",
        "model=NeuralNetworkBinaryClass(in_size=28*28,hidden_size=5)\n",
        "criterion=nn.BCELoss()"
      ],
      "metadata": {
        "id": "tBNYW-2_YHJ4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
